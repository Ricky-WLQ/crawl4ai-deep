# ============================================================
# Crawl4AI Hybrid BFS Crawler v3.8.0 - Environment Variables
# ============================================================
# This is a TEMPLATE file - do NOT put real API keys here!
# Copy this to .env and fill in your actual keys
#
# IMPORTANT: Add .env to .gitignore!
#   echo ".env" >> .gitignore

# ============================================================
# REQUIRED: DeepSeek API Key
# ============================================================
# Get your API key from: https://platform.deepseek.com/
# Used for: Generating answers with deepseek-reasoner
# Format: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ============================================================
# OPTIONAL: OpenRouter API Key
# ============================================================
# Get your API key from: https://openrouter.ai/
# Used for: Additional semantic re-ranking (75% semantic + 25% keyword)
# Model: qwen/qwen3-embedding-8b
# Format: sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
#
# Without this key:
#   - Local embeddings will be used for ranking
#   - Application still works, slightly less accurate
OPENROUTER_API_KEY=your_openrouter_api_key_here

# ============================================================
# OPTIONAL: Server Port
# ============================================================
# Default: 8080
# Zeabur: Auto-configured, usually don't override
PORT=8080

# ============================================================
# v3.8.0 ARCHITECTURE - HYBRID BFS + SEMANTIC
# ============================================================
#
# 1. BFSDeepCrawlStrategy (max_depth=3)
#    - Breadth-First Search for systematic exploration
#    - Explores ALL links at each level before going deeper
#    - Guarantees finding sibling pages (all law docs at same level)
#
# 2. SPA-Friendly Configuration
#    - wait_for="css:body" for JavaScript rendering
#    - process_iframes=True for embedded content
#    - delay_before_return_html=2.0s for JS execution
#
# 3. Local Semantic Scoring
#    - Model: paraphrase-multilingual-mpnet-base-v2
#    - Supports 50+ languages (Chinese, English, etc.)
#    - NO API calls during crawling
#
# 4. OpenRouter Re-ranking (optional)
#    - Additional semantic refinement
#    - 75% semantic + 25% keyword weighting
#
# 5. DeepSeek Answer Generation
#    - Model: deepseek-reasoner
#    - Comprehensive answers from crawled content
#
# ============================================================
# WHY BFS OVER DFS?
# ============================================================
# BFS (Breadth-First Search):
#   Level 0: Start page
#   Level 1: ALL links from start page (crawled first)
#   Level 2: ALL links from level 1 (crawled second)
#   Level 3: ALL links from level 2 (crawled third)
#   Result: Finds ALL law documents at each level
#
# DFS (Depth-First Search):
#   Goes deep on FIRST link only, then backtracks
#   May miss important sibling links
#   Example: Clicks "About Us" first, goes 3 levels deep
#            into staff pages, never reaches actual laws
#
# For hierarchical legal sites like Macau laws:
#   BFS GUARANTEES reaching go.asp?d=lei-17-2009cn
#   DFS MAY MISS IT depending on link order
# ============================================================

# ============================================================
# API USAGE EXAMPLE
# ============================================================
# POST /crawl
# {
#   "start_url": "https://bo.dsaj.gov.mo/",
#   "query": "販毒罪 刑罰",
#   "max_pages": 100,
#   "max_depth": 3,
#   "use_embeddings": true
# }
#
# Response:
# {
#   "success": true,
#   "answer": "According to the crawled content...",
#   "confidence": 0.85,
#   "pages_crawled": 75,
#   "sources": [...],
#   "crawl_strategy": "hybrid_bfs"
# }
# ============================================================

# ============================================================
# DEPLOYMENT
# ============================================================
# Local:
#   cp .env.example .env
#   # Edit .env with your API keys
#   pip install -r requirements.txt
#   python main.py
#   # Access at http://localhost:8080/docs
#
# Docker:
#   docker build -t crawl4ai:v3.8.0 .
#   docker run --env-file .env -p 8080:8080 crawl4ai:v3.8.0
#
# Zeabur:
#   - Push to GitHub
#   - Connect repo in Zeabur
#   - Add environment variables in dashboard
#   - Deploy automatically
# ============================================================
