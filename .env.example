# Crawl4AI Adaptive Crawler v3.6.0 Environment Variables
# This is a TEMPLATE file - do NOT put real API keys here!
# Copy this to .env and fill in your actual keys

# ============================================================
# REQUIRED: DeepSeek API Key for answer generation
# ============================================================
# Get your API key from: https://platform.deepseek.com/
# Used for: Generating comprehensive answers from crawled content
# Model: deepseek-reasoner (advanced reasoning)
DEEPSEEK_API_KEY=your_deepseek_api_key_here

# ============================================================
# OPTIONAL: OpenRouter API Key for re-ranking phase
# ============================================================
# Get your API key from: https://openrouter.ai/
# Model used: qwen/qwen3-embedding-8b (high-quality embeddings)
#
# RE-RANKING PHASE (optional but RECOMMENDED):
#   - After crawling, re-ranks pages by semantic similarity
#   - Uses OpenRouter embeddings for high-quality scoring
#   - Helps surface the most relevant content (SOLUTION 3)
#   - Weighting: 75% semantic + 25% BM25 (SOLUTION 3 improvement)
#
# Without OpenRouter:
#   - Uses crawl scores only (still works, less accurate)
#   - Skips re-ranking phase automatically
OPENROUTER_API_KEY=your_openrouter_api_key_here

# ============================================================
# OPTIONAL: Server port (Zeabur sets this automatically)
# ============================================================
# Default: 8080
# On Zeabur: Usually auto-configured as 8080
PORT=8080

# ============================================================
# v3.6.0 IMPROVEMENTS (All Solutions Applied)
# ============================================================
#
# SOLUTION 1: Aggressive Stopping Prevention
#   - confidence_threshold=0.05 (5% instead of 70%)
#   - min_relative_improvement=0.01 (1% instead of 10%)
#   - Prevents early termination before finding relevant pages
#   - Result: Crawls 40-50+ pages instead of stopping at ~13
#
# SOLUTION 2: Better Embedding Model for Legal Documents
#   - UPDATED: paraphrase-multilingual-mpnet-base-v2
#   - Previous: paraphrase-multilingual-MiniLM-L12-v2 (MiniLM)
#   - Better semantic understanding of complex legal terminology
#   - More accurate for Chinese legal documents
#   - Supports 50+ languages including Chinese, English, etc.
#
# SOLUTION 3: Better Re-ranking Weights
#   - UPDATED: 75% semantic + 25% BM25 (was 60/40)
#   - Trusts embedding model more than keyword matching
#   - Better for legal domain where surface keywords ≠ relevance
#
# SOLUTION 4: More Query Variations
#   - UPDATED: n_query_variations=20 (was 5)
#   - Better coverage of synonyms and related terms
#   - Especially important for Chinese queries
#
# SOLUTION 5: Deeper Crawling
#   - UPDATED: max_pages=50 (was 20)
#   - UPDATED: top_k_links=25 (was 15)
#   - Explores more of the website structure
#   - Discovers pages like lei17_cn.asp that were previously skipped
#
# SOLUTION 6: Proper Content Extraction
#   - Ensures .asp files are properly parsed
#   - Fixed markdown generation for legal documents
#   - Better term extraction for saturation detection
#
# ============================================================
# EMBEDDING STRATEGY - Runs LOCALLY (NO API NEEDED!)
# ============================================================
#
# LOCAL MULTILINGUAL MODEL:
#   - sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (SOLUTION 2)
#   - Runs entirely on your server
#   - No API calls for embeddings during crawling
#   - Supports 50+ languages including:
#     * Chinese (Simplified & Traditional)
#     * English
#     * Portuguese
#     * And 45+ more
#
# CRAWLING PROCESS:
#   1. Start URL → Extract links
#   2. Rank links by semantic similarity (LOCAL embeddings)
#   3. Visit highest-scoring links
#   4. Extract content from each page
#   5. Continue until max_pages reached (SOLUTION 1: aggressive)
#
# RE-RANKING PHASE (Optional - requires OPENROUTER_API_KEY):
#   1. Use OpenRouter to get embeddings for all crawled pages
#   2. Re-rank by semantic similarity to query (SOLUTION 3: 75% weight)
#   3. Select top pages for answer generation
#
# ANSWER GENERATION:
#   1. Format top pages into context
#   2. Send to DeepSeek-reasoner with system prompt
#   3. Generate comprehensive answer with citations
#
# ============================================================
# SETUP INSTRUCTIONS
# ============================================================
#
# 1. Copy this file to .env:
#    cp .env.example .env
#
# 2. Get API Keys:
#    a) DeepSeek: https://platform.deepseek.com/
#       - Required for answer generation
#       - Create API key in console
#    
#    b) OpenRouter: https://openrouter.ai/
#       - Optional but recommended for better results
#       - Create API key in settings
#       - Choose pricing model (pay-as-you-go recommended)
#
# 3. Fill in your keys in .env:
#    DEEPSEEK_API_KEY=sk-xxxxxxxxxxxx
#    OPENROUTER_API_KEY=sk-or-xxxxxxxxxxxx
#    PORT=8080
#
# 4. Start the application:
#    docker run --env-file .env -p 8080:8080 crawl4ai-fixed:v3.6.0
#
# ============================================================
# PRICING ESTIMATES (Monthly)
# ============================================================
#
# DeepSeek-reasoner:
#   - ~$0.50-2.00 per 1M tokens
#   - Typical query: 1-2K tokens
#   - Estimate: $2-5/month for light use, $20-50/month for heavy use
#
# OpenRouter (qwen3-embedding-8b):
#   - ~$0.02 per 1M tokens (very cheap)
#   - Typical crawl: 10-15 pages re-ranked = ~10K tokens
#   - Estimate: $0.20-0.50/month for light use
#
# Total: ~$2-5/month for casual use, $20-60/month for heavy crawling
#
# ============================================================
# EXAMPLE API KEY FORMAT (DO NOT USE REAL KEYS HERE!)
# ============================================================
#
# DeepSeek API Key format:
#   sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (typically 32+ chars)
#
# OpenRouter API Key format:
#   sk-or-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx (typically 35+ chars)
#
# ============================================================
# TROUBLESHOOTING
# ============================================================
#
# Q: "DEEPSEEK_API_KEY not set" error
#   A: Make sure .env file exists and DEEPSEEK_API_KEY is filled in
#      Check: cat .env | grep DEEPSEEK_API_KEY
#
# Q: "No pages crawled" or crawler stops early
#   A: SOLUTION 1 ensures aggressive crawling now
#      Old behavior: stopped at ~13 pages
#      New behavior: crawls 40-50+ pages
#
# Q: "Lei documents not found"
#   A: SOLUTION 5 (deeper crawling) now discovers these pages
#      Old: max_pages=20, top_k_links=15
#      New: max_pages=50, top_k_links=25
#
# Q: "Low semantic scores on legal documents"
#   A: SOLUTION 2 (mpnet model) handles legal terminology better
#      Old model: MiniLM (lightweight, faster but less accurate)
#      New model: mpnet-base (better legal document understanding)
#
# ============================================================
# DOCKER SETUP
# ============================================================
#
# Build:
#   docker build -t crawl4ai-fixed:v3.6.0 .
#
# Run with environment variables:
#   docker run -p 8080:8080 \
#     -e DEEPSEEK_API_KEY="your_key" \
#     -e OPENROUTER_API_KEY="your_key" \
#     crawl4ai-fixed:v3.6.0
#
# Or use .env file:
#   docker run --env-file .env -p 8080:8080 crawl4ai-fixed:v3.6.0
#
# Check health:
#   curl http://localhost:8080/health
#
# View logs:
#   docker logs <container_id> -f
#
# ============================================================
# ZEABUR DEPLOYMENT
# ============================================================
#
# 1. Push to GitHub
# 2. Connect GitHub repo to Zeabur
# 3. Set environment variables in Zeabur console:
#    - DEEPSEEK_API_KEY
#    - OPENROUTER_API_KEY
#    - PORT (Zeabur usually sets this automatically)
# 4. Zeabur will auto-build and deploy
# 5. Access at: https://your-app.zeabur.app/docs
#
# ============================================================
