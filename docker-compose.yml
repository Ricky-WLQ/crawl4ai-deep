version: '3.8'

services:
  crawl4ai:
    # ============================================================================
    # IMAGE CONFIGURATION
    # ============================================================================
    image: unclecode/crawl4ai:latest
    container_name: crawl4ai-prod
    pull_policy: always  # Always pull latest image for security patches
    
    # ============================================================================
    # PORT MAPPING
    # ============================================================================
    ports:
      - "11235:11235"
    
    # ============================================================================
    # ENVIRONMENT VARIABLES
    # ============================================================================
    environment:
      # Core Settings
      - PORT=11235
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # API Keys & Authentication
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - CRAWL_API_KEY=${CRAWL_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - REQUIRE_API_KEY=${REQUIRE_API_KEY:-true}  # Enable auth in production
      
      # Crawler Configuration (Optimized for Production)
      - MAX_PAGES=${MAX_PAGES:-100}
      - MAX_DEPTH=${MAX_DEPTH:-3}
      - REQUEST_TIMEOUT_SECONDS=${REQUEST_TIMEOUT_SECONDS:-60}
      - MEMORY_THRESHOLD_MB=${MEMORY_THRESHOLD_MB:-500}
      - MAX_CONCURRENT_REQUESTS=${MAX_CONCURRENT_REQUESTS:-3}
      - BROWSER_POOL_SIZE=${BROWSER_POOL_SIZE:-3}
      
      # Security & CORS
      - CORS_ORIGINS=${CORS_ORIGINS:-https://yourdomain.com}  # Restrict in production
      - ALLOWED_DOMAINS=${ALLOWED_DOMAINS:-}  # Optional domain whitelist
      
      # Performance Tuning
      - CACHE_TTL_SECONDS=${CACHE_TTL_SECONDS:-3600}
      - ENABLE_CACHING=${ENABLE_CACHING:-true}
      - GZIP_ENABLED=${GZIP_ENABLED:-true}
    
    # ============================================================================
    # VOLUMES - Persistent Data & Logs
    # ============================================================================
    volumes:
      # Logs - persists across restarts
      - crawl4ai-logs:/app/logs
      
      # Browser cache - speeds up subsequent requests
      - crawl4ai-cache:/app/.cache
      
      # Browser data - maintains cookies/sessions
      - crawl4ai-browser-data:/app/.browsers
      
      # Shared memory for Chromium (critical performance)
      - /dev/shm:/dev/shm
    
    # ============================================================================
    # SHARED MEMORY - REQUIRED FOR CHROMIUM
    # ============================================================================
    shm_size: 2gb
    
    # ============================================================================
    # RESOURCE LIMITS - Production-Grade Configuration
    # ============================================================================
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8g
        reservations:
          cpus: '2'
          memory: 4g
    
    # ============================================================================
    # RESTART POLICY - Auto-recovery
    # ============================================================================
    restart: unless-stopped
    
    # ============================================================================
    # HEALTH CHECK - Ensures service availability
    # ============================================================================
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11235/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s  # Give container time to start
    
    # ============================================================================
    # LOGGING - Structured JSON logging with rotation
    # ============================================================================
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "10"
        labels: "service=crawl4ai"
    
    # ============================================================================
    # NETWORK & SECURITY
    # ============================================================================
    networks:
      - crawl4ai-network
    
    # Optional: Add security options for hardened deployments
    security_opt:
      - no-new-privileges:true
    
    # ============================================================================
    # ENVIRONMENT FILE
    # ============================================================================
    env_file:
      - .env.production

# ============================================================================
# NAMED VOLUMES
# ============================================================================
volumes:
  crawl4ai-logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./logs
  
  crawl4ai-cache:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./.cache
  
  crawl4ai-browser-data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./.browsers

# ============================================================================
# NETWORKS
# ============================================================================
networks:
  crawl4ai-network:
    driver: bridge
